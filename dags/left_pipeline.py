"""
left_pipeline
DAG auto-generated by Astro Cloud IDE.
"""

from airflow.decorators import dag
from astro import sql as aql
from astro.table import Table, Metadata
import pandas as pd
import pendulum

import path

"""
Write your markdown hereâ€¦
| Format | Suffix | Description |
|:--|:--|:--|
| Avro | .avro | Binary file format for storage and serialization |
| Parquet | .parquet | Columnar storage file format  |
| ORC | .orc | Optimized Row Columnar file format |
"""

@aql.dataframe(task_id="root_node")
def root_node_func():
    import path

@aql.run_raw_sql(conn_id="duckdb_default", task_id="dwd_users", handler=lambda x: pd.DataFrame(x.fetchall(), columns=x.keys()))
def dwd_users_func():
    return """
    
    """

@aql.run_raw_sql(conn_id="duckdb_default", task_id="dwd_logs", handler=lambda x: pd.DataFrame(x.fetchall(), columns=x.keys()))
def dwd_logs_func():
    return """
    
    """

@aql.run_raw_sql(conn_id="duckdb_default", task_id="dws", handler=lambda x: pd.DataFrame(x.fetchall(), columns=x.keys()))
def dws_func():
    return """
    
    """

@aql.run_raw_sql(conn_id="duckdb_default", task_id="ads", handler=lambda x: pd.DataFrame(x.fetchall(), columns=x.keys()))
def ads_func():
    return """
    
    """

@dag(
    schedule="0 0 * * *",
    start_date=pendulum.from_format("2023-04-14", "YYYY-MM-DD").in_tz("UTC"),
)
def left_pipeline():
    root_node = root_node_func()

    dwd_users = dwd_users_func()

    dwd_logs = dwd_logs_func()

    dws = dws_func()

    ads = ads_func()

    ads << dws

    dwd_logs << root_node

    dwd_users << root_node

    dws << [dwd_users, dwd_logs]

dag_obj = left_pipeline()
